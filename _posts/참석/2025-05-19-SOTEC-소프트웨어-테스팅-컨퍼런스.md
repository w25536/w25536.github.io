---
title: "SOTEC 2025 소프트웨어 테스팅 컨퍼런스"
last_modified_at: 2025-05-19
categories:
  - 
tags:
  - 
excerpt: "SOTEC 2025 소프트웨어 테스팅 컨퍼런스"
use_math: true
classes: wide
---


10: 10 개화사 

## 컨퍼런스 세션 목록

### 1. [기조연설] AI시대의 소프트웨어 테스팅-안전과 신뢰를 넘어 올리까지
- 발표자: ETRI AI전연구소, 김명주 소장
- 주요 내용:
	- 안전과 신뢰를 넘어 ‘윤리’까지
		- [Evaluation]딥페크 및 테스팅 해결 방법을 찾는걸 모색 (편향, 문화적 차이)
		- 비가역성 
		- AI 기준이 달라 테스팅하기 힘들다 - 윤리가 곧 법이다
		- 소프트웨어에서의 Security, Safety, Soundness (malfunction 검증 단계) soft testing 할 수 없다. soundness 특히 어렵다. (풀어쓰면 좋을듯)
		- 인공지능(AI)에서의 Security, Safety, Trustworthiness (자연재해 일어났을때 잘 작동, 건전성)
		- AI는 완벽하게 만들지 않았으니 당연히 힘들다...
		- Bias, 악용, 
		- Systemic Risks (Labor market, Global R&D divide, Market concentration, Environment, Privacy, Copyright) - 사회적 파장, 가장 어렵다. 
		- AI Security - 국가 전체를 위험에 빠트릴 수 있다. (National Security)
		- 
![[CleanShot 2025-05-20 at 10.38.49@2x.png]]

![[CleanShot 2025-05-20 at 10.40.43@2x.png]]

- 데이터 셋이 중요하다 CTF (공격 목표를 찾는)
- 하위 도구도 다르고 데이터셋도 다르고 평가 도구 
- 사실 표준 싸움 
- 집단(국가) 편향성 (fine-tunning)으로 해결한다. 
- 인공지능안전연구소(Korea AISI) (지능 연구원만들어야 되는데 왜? 안전?)
- 앞으로 모든 안전진단을 한다고 한다다...




### 2. 안전하고 신뢰할 수 있는 생성형 인공지능 개발 및 검증
- 발표자: KAIST 유창동 교수
- 주요 내용:
  - 인공지능의 공정성 
  - 인공지능이 사람을 뛰어 넘기 시작 
  - Chatbot arena leaderboard (https://huggingface.co/spaces/lmarena-ai/chatbot-arena-leaderboard)
  - 정책 생성 (Physical AI)
  - 다양한 생성형 AI 데모
  - 생성형  AI의 문제점 편향 된 시선(간호사 -> 여자  , 변호사 -> 남자  예시) (영화, 광고, AR/VR, 교육 등 )
  - FAT (F: A : T:transparent)
  - 데이터 편향 모델 편향 출력의 편향 
  - MAF, 과기정통부 AI 공정성 기술 - MSIT AI Fair 
	  - 편향성을 분석하고 완화하는 프레임 워크 공개 
  - 새로운 대통량 임기 떄마다 바뀌는 공정성 제약이 힘들게 한다...
  - 확각, 탈옥, 편향 (가장큰 문제) 교수왈 MAF 써서 해결 가능 ...
  - 근본적을 데이터셋이 믿을수 있어야되고 augmentation을 잘해야 된다. 
  - 생성형 AI (RHIF , RAG, )
  - 공정성 문제가 해결 된다 하더라도 끝없는 비용 부담이 일어남 
  - GPU 사용량으로 인한 환경 오염 
  - 인터넷의 오염 

### 3. 국내 AI 서비스의 품질 인증 제고 방안
- 발표자: TTA AI융합시험인증소 김영문 소장
- 주요 내용:
  - Anthropic RSP 
  - 사이버보안 (Cybersecurity), CBRN Inofrmation, 모델 자율성 (Model Autonomy)
  - Human Feedback Evanlutations
  - Red teaming
  - BBQ Bisas Bench for QA Eval 
  - 등등....
  - 개발 안내서를 만들었다고 한다....
  - 제 3자 품질 검증도 한다.
  - 

### 4. AI 데이터 프로파일링과 품질 확보 전략 및 사례
- 발표자: 미소정보기술 손진호 CTO
- 주요 내용:
  - 데이터 폭발적으로 늘어 나는
  - 데이터 양에서 데이터 질로 변화 
  - 데이터 활용성 높이려면 지속적인 품질 관리 뒤따라야 한다. 
  - 
![[CleanShot 2025-05-20 at 13.36.01@2x.png]]

![[CleanShot 2025-05-20 at 13.37.37@2x.png]]

![[CleanShot 2025-05-20 at 13.46.14@2x.png]]
### 5. LLM 품질, 과정보다 결과로 증명한다 - 한국형 LLM 프롬프트 테스트 사례
- 발표자: 와이즈스톤 윤종운 수석연구원
- 주요 내용:
  - 
  - 신뢰성 고도화 진행 중 
  - 신뢰도 상승을 위해 기업들이 계속해서 투자중 
  - 
  - ![[CleanShot 2025-05-20 at 14.03.56@2x.png]]
  - 정답 기반으로 LLM 평가한다. 

### ![[CleanShot 2025-05-20 at 14.07.12@2x.png]]

앙상블 평가 방식이 좋으니 그거 써라 과접합도 낮고 

![[CleanShot 2025-05-20 at 14.16.10@2x.png]]
1. 국제 표준 기반의 생성형 AI 신뢰성 관련 특성 이해
	1. 공정성, 안정성, 무해성
2.  객관성 있는 학습 및 평가 데이터 구축을 위한 국내 법률 참조
	1. 국가인권위원회법, 정보통신에 과한 심의 규정, 국가법령정보센터의 정보통신망 이용촉진 등에 과한 법률 등
3. 프롬프트 기반 자동 평가 환경 구축 
	1. 오픈소르 LLM을 활용한 앙상블 평가 모델 설계 및 평가 방식 확인


4. 인공지능 품질 향상을 위한 비정형데이터 검증 방법
- 발표자: 아이삭 김상복 대표
- 주요 내용:
	  - 
  - 
  - 

### 7. 한국적 AI, LLM 품질 및 Eco 협업
- 발표자: KT 박재형 상무
- 주요 내용:
  - 한국어 되는 모델  이해대한 관계의 대한 모델을 사용할때 힘들다 
  - 작은 사이즈 모델을 사용해도 SOTA 글로벌 모델 비교 해도 않좋다 
  -  국 가 / 기 업 / 개 인 이 A 를 가 장 잘 활 용 할 수 있 는 토 대 를 제 공
• K T 는 국 민 들 의 일 상 의 변 화 , 산 업 계 의 혁 신 을 리 딩 하 는 한 국 적 A 를 준 비
  - 한국에 맞는 AI 만드는게 중요하다. 
  - KT SLM 모델 만드는 목표로 하고 있다. 
  - KT는 믿음 LLM 모델을 사용한다
  - Agent -> gpt perplextiy 다 playground 형식 agentic AI
  - 안 전 하 고 투 명 한 K - A I 를 보 장 하 는 R A l F r a m e w o r k(Governance, Principles, Process, People)
  - saftety guardrail 
![[CleanShot 2025-05-20 at 15.35.10@2x.png]]
### ![[CleanShot 2025-05-20 at 15.35.56@2x.png]]

- 모델에다가 냅따 데이터를 떄려 박는게 아니고 목표를 정하고 데이터를 모으고 모은 데이터를 학습한다.
- ![[CleanShot 2025-05-20 at 15.37.24@2x.png]]
정략적인 평가를 해도 결과가 안좋을 수 도 있어 정석적 평가도 같이 해야된다. 

![[CleanShot 2025-05-20 at 15.39.46@2x.png]]

KT에서도 평가 데이터셋 2급 보호 고 서로 공유 해서는 안된다. 



8. VUX 기반 AI Contact Center의 테스트 자동화 방안
- 발표자: 티벨 이혜진 연구소장
- 주요 내용:
  - 
  - 
  - 

### 9. AI 시스템의 품질평가를 위한 측정 및 가이던스 국제 표준 소개 및 개발 현황
- 발표자: KTL 안선호 팀장
- 주요 내용:
  - 
  - 
  - 
---

[ClovaNote Sharing]

Sotec 1교시
https://clovanote.naver.com/s/hjXRUD3Dp63vMgkfBUeeY4S
Password: ib8unn



- 00:00~02:32
    
    AI 서비스 프로그램의 완벽한 품
    
    - AI 서비스 프로그램들을 어떻게 완벽하게 고객이나 소비자가 원하는 품에 올려놓을 것이냐는 부분이 이슈가 되고 있다고 생각함
    - 오늘 컨퍼런스가 의미가 있다고 생각함
    - 한국진흥정보사회진흥원 한종성 원장님의 축사를 들음
    
- 03:33~06:50
    
    AI의 한계
    
    - AI는 좋기는 좋은데 안을 들여다볼 수가 없음
    - AI는 하나의 어떤 획일적인 상품이나 품질 기준 같은 것을 적용할 수 없고 사람 쓰는 사람마다 아니면 이 경우마다 굉장히 다른 품질 기준과 안전 기준이 적용해야 되기 때문에 예를 들어 기존에 우리가 소프트웨어를 타임 원타임 테스트를 했다고 그러면 이건 컨티뉴스하게 사실임
    - AI가 쓰는 동안 내내 계속 검증이 돼야 되고 검증의 기록 남아서 혹여라도 있을 어떤 사고라든가 피해라든가 이런 것들을 대응을 해야 되는 게 굉장히 중요한 영역임
    
- 07:39~10:30
    
    인공지능 안전 연구소 소장
    
    - AI 기본법에 의해서 인공지능 안전 연구소가 설립이 되면서 초대 소장으로 6개월째 일을 하고 있음
    - 앞에서 축사해 주셨던 두 분께서 굉장히 힘들 거라 앞으로 테스트가 그런 이야기를 하는데 현장에서 막상 일을 하다 보니까 정말 힘듦
    - 디지털 기술 AI를 포함해서 이 기술이 출연을 하면 양면성이 있음
    - 긍정적인 면이 있지만 역기능과 부작용들이 있음
    
- 11:21~12:14
    
    AI의 윤리적 평가
    
    - AI는 생각하는 사람마다 정의가 다 다르기 때문에 객관적인 입장에서 테스팅 한다는 건 굉장히 힘든 상황임
    - 윤리를 굉장히 강조를 함
    - 윤리적인 AI를 어떻게 평가할지 고민을 가지고 있음
    
- 13:01~16:18
    
    EU, AI 법 개정
    
    - 소프트웨어 수요자가 발주를 해서 개발을 하게 되면 윗단에서 제대로 움직이는지 정확성 성능 평가를 하고 밑단에서 위험성 평가를 함
    - 이용자 단에서는 제대로 되는 걸 줬음에도 불구하고 그것 때문에 또 다른 문제들이 생길까 윤리적인 문제나 부작용이 생길까 하는 부분들까지 감안하는데 그걸 보통 사우드니스라고 함
    - EU가 AI 법을 개정하기 전에 첫 번째 버전이 집행유예가 됐던 버전임
    - EU 버전에서 인공지능을 정의를 할 때 소프트웨어라고 정의를 함
    - EU에서는 사운드니스 대신에 트러스티 워디라는 말을 씀
    - AI에 관한 어떤 테스팅을 할 때 신뢰성 센터 신뢰할 수 있는 AI라는 표현을 했던 가장 큰 이유는 저쪽에 있는 트로스트 워스라는 개념 가지고 들어간 상태임
    
- 17:09~18:56
    
    구글, AI 오픈
    
    - 구글이 오픈 AI보다 세트 피트보다 훨씬 좋은 성능이 좋은 AI를 갖고 있음
    - 오픈하지 않는 이유는 잠재적인 사회적 윤리적 위험을 통제할 수 있는 방법을 찾을 때까지 오픈하지 않기로 결정함
    - 구글이 열흘 만에 오픈을 해버림
    - 구글 부사장 제프 린튼이 5월에 사표를 내고 10년 동안의 구글 부사장을 그만두고 나옴
    
- 19:37~22:54
    
    AI의 부작용
    
    - 세모토만 오픈ai의 대표적 실제 만들었던 사례는 유료 사용자들한테 돈을 받기 위해서 업그레이드를 함
    - AI가 사람이 불완전한데 AI라고 완전하겠냐는 어록이 있음
    - AI로 인한 부작용과 역기능 때문에 규제를 해야 된다는 이야기를 함
    
- 23:34~25:19
    
    AI 시큐리티의 개념
    
    - AI 테스팅 할 때 안전이라는 말을 정의를 하는데 인공지능과 관련하여 발생할 수 있는 위험으로부터 국민의 생명 신체 재산 등을 보호하고 사회가 신뢰 기반으로 움직일 수 있는 상태를 안전한 상태라고 함
    - 안전 테스트 가운데서 연구에서 말했던 것처럼 불량 위험 악용 위험 사회적 위험이라고 볼 때 특히 악용 이용 쪽은 최근에 이런 관점이 있음
    - AI가 그동안 몇 년 동안 성숙할 만큼 성숙했기 때문에 AI가 잘 못 만들어지는 거에 대한 관심을 이제는 두지 말자라는 관점임
    - 나쁘게 쓰는 거에 초점을 맞춰야겠다 해서 끌어올린 게 보통 AI 시큐리티임
    
- 26:06~28:38
    
    AI로 인한 위험
    
    - AI 때문에 생기는 위험이 34%나 됨
    - AI 때문에 생기는 위험을 평가하기 위해 리스크 맵을 만들고 있음
    - 리스크 맵은 한국적인 상황도 고려가 되면서 글로벌 스탠더드를 만들려고 생각하고 있음
    
- 29:26~30:19
    
    데이터셋의 평가
    
    - 데이터 셋이 굉장히 중요하고 평가 부분도 인스펙터라든지 몇 개가 공개돼 있음
    - 공개된 거 외에 어떤 걸 평가하느냐에 따라서 평가 도구가 조금씩 달라짐
    - 도구가 하나로 모여지지 않음
    
- 31:05~34:47
    
    AI의 답의 영역 제한
    
    - AI의 답의 영역들을 제한하지 않으려면 객관식으로 문제를 내야 함
    
- 35:38~38:45
    
    AI 안전연구소의 역할
    
    - AI 안전연구소는 AI 기업을 위로 올려주는 역할을 함
    - AI 안전연구소는 AI 나오는 것마다 버전마다 안전 보고서를 다 만들 생각임
    - AI 안전연구소는 기업을 도와주는 조직으로서 활동을 할 생각을 가지고 있음
    
- 39:00~42:33
    
    인공지능의 정의
    
    - 인공지능은 다양한 영역에서 정보가 많이 활용되고 있음
    - 인공지능에 대해서 다양한 정의가 있음
    - 인지 추론 행동을 하는 소프트웨어가 인공지능임
    
- 44:03~53:27
    
    딥마인드의 생성 모델
    
    - 딥마인드의 창시자는 10배 100배 더 커질 것이라고 얘기를 하고 있음
    - 리더 보드는 인공지능이 가장 우수한 다양한 벤치마크 데이터셋에 어느 정도의 성능을 내고 있나를 보는 것임
    - 생성 모델은 언어가 있고 그린 비디오 아카이브 음성도 만들어 코드도 잘 만들어져 있음
    - 정책이라는 것은 어떤 상황에 놓여 있을 때 어떠한 행동을 취해야 될 것인지가 정책이라고 볼 수 있음
    - 생성형 AI 시대는 테스트의 해법을 제시함
    
- 53:42~57:34
    
    인공지능의 편향성
    
    - 인공지능은 과거를 보고 학습을 하고 거기에 맞게 생성을 하는데 편향된 시각을 갖고 있는 것이 문제임
    - 편향된 시각을 갖고 있는 것이 앞으로 내다쳤을 때 시대가 모든 것을 다 허용하는 젠더가 바이너리 젠더가 아님
    - 다양한 주제의 법 단체 학회 노력을 하고 있음
    
- 59:07~01:06:26
    
    편향성을 검증할 수 있는 데이터셋
    
    - 믿을 수 있는 데이터셋을 구축을 해야 됨
    - 편향성을 자체적으로 찾을 수 있도록 노력을 해야 됨
    - 편향성 기준 자체 수립하는 것이 중요함
    - 편향성을 검증할 수 있는 데이터셋이 만들어져야 됨
    
- 01:08:01~01:10:11
    
    카이스트, AI 서비스 품질 인증 제고 방안 발표
    
    - 카이스트 유창동 교수님이 AI 서비스의 품질 인증 제고 방안에 대해 발표함
    - 한국정보통신기술협회 AI 융합 시험연구소 김영문 연구소장님이 신뢰할 수 있는 AI 시험 인증서 현황 및 향후 계획을 소개함
    - 미국의 사고 관련된 보고 통계를 참고하면 AI 관련된 사고가 증가하고 있음
    
- 01:11:28~01:12:24
    
    인공지능의 성능
    
    - 인공지능의 신뢰성 안전성도 중요하지만 기본적인 건 성능이 어느 정도 받춰져야지만 사실은 인공지능 서비스에 대해서 우리 소비자들이 다가갈 수 있고 안전 신뢰성 문제가 또 생기는 게 아닐까라는 차원에서 성능에 대한 이슈가 있음
    
- 01:12:54~01:15:03
    
    AI의 일상화
    
    - AI의 일상화 계획들을 액션 플랜들을 많이 발표를 했으니까 참고하시면 좋을 것 같음
    - AI 기술이 프론트오 AI로 계속 폭발적으로 발전함에 따라서 리스크도 비례적으로 증가를 함
    - 민간 차원의 자율 규제도 필요하고 정부 차원에서도 규제가 어느 정도 있어야 됨
    - 제3자 검증도 필요한 이유가 이 슬라이드를 보면서 이해를 했으면 해서 가져왔음
    
- 01:16:05~01:19:32
    
    네이버, 카카오의 안전한 AI 모델 개발
    
    - 엔트로픽은 왜 윤리적으로 선제적으로 여러 가지 활동을 많이 하는지 파악하지 못함
    - 엔트로픽은 자체적으로 자율 규제 프로토콜을 만들어서 하고 있음
    - 국내에 네이버나 카카오 또 일반 중소 벤처 업체들의 경우도 자체 안전 세이프티 프레임웍을 만들어서 평상시에 점검을 하면 제3자가 정부 사업에 입찰을 하거나 할 때 우리는 안전하게 AI 모델을 개발해서 운영하고 있다라는 걸 자기 입증을 할 수 있음
    - 시큐리티 AI의 보안성 문제에 대해 설명하고 있음
    
- 01:20:09~01:25:01
    
    AI 모델 공격 패턴
    
    - API를 이용할 경우 반복적으로 프로포트를 날리면서 모델을 유사하게 만들 수 있음
    - 적대적인 공격이나 AI 모델을 무력화시킬 수 있음
    - 데이터 자체를 오염시키는 방법도 하나의 공격 패턴으로 나옴
    - 개발 안내서를 만들어서 업그레이드를 하고 있음
    - 민간 자율의 시험 인증 서비스를 2년 전부터 제공하고 있음



**단락별 요약

**

평가 전더보기

- 00:00~01:06
    
    데이터 기술 요소의 증가
    
    - 데이터 기술 요소는 데이터를 폭발적으로 증가시키고 있음
    - 데이터 플랫폼들이 데이터를 증가시키는 가장 큰 역할을 하고 있음
    - 생성형 AI의 등장이 바로 이러한 부분에서의 또 하나의 주축이라고 판단을 하고 있음
    
- 02:02~02:55
    
    데이터 품질 관리의 중요성
    
    - 데이터 품질을 잘 확보하고 데이터를 잘 활용했을 때 의사결정 지원에 큰 역할을 할 수 있음
    - 데이터 응답 시스템을 체크할 수 있는 비용 절감, 운영 효율성, 비즈니스 경쟁력 강화 부분에서 영향을 갖출 수 있고 효과를 볼 수 있음
    - 데이터 양에서 데이터 질로 변한다는 것을 꼭 말씀드리고 싶었음
    
- 03:49~06:36
    
    데이터 품질 관리
    
    - 데이터 확대되는 사업들은 굉장히 늘어나고 많은 관심을 받고 있음
    - 나라의 RND 투자라든가 사업 원에서 생산형 AI가 빠질 수 없는 키워드 중에 하나임
    - 데이터의 신뢰성과 활용성을 높이기 위해서는 지속적인 품질 관리를 해야 됨
    - 데이터 품질 관리를 하기 위해서 굉장히 많은 시간을 드리고 솔루션이나 소프트웨어를 사용하고 있음
    
- 07:31~08:31
    
    표준화의 중요성
    
    - 지속적 품질 관리를 하기 위해서 표준화는 코드화가 먼저 되고 메타를 잘 설정해야 됨
    - 표준 시스템이 운영이 되면 표준화가 진행이 됨
    - 품질 관리에 대해서 절차를 정리해 봄
    
- 09:28~13:35
    
    데이터 품질 향상을 위한 방법
    
    - 데이터 품질 향상을 위해서는 오류 탐지나 개선이 필요함
    - 데이터 표준화나 일관성을 확보해서 잘 관리할 수 있게 해야 함
    - 지속적 검사를 위해서 품질 검사 양이나 모니터링을 활성화시킬 건데요 부문에서도 데이터 양을 변화하면서 측정을 하자 왜냐하면 전체 100이면 1 모두가 무결성을 가지고 측정하는 부분도 있겠지만 샘플링을 통해서 스팟성으로 하는 것도 하나의 전략적으로 측정할 수 있는 부분이라고 제시 드릴 수 있을 것 같음
    
- 14:30~15:21
    
    데이터 프로파일링의 필요성
    
    - 데이터 프로파일링은 이상 수치라든가 중복값 데이터를 기본적으로 발견하고 패턴이나 규칙의 일관성에 문제가 있는지를 보고 유지시켜주면 됨
    - 데이터 이해도를 항상 시킬 수 있는 부분, 지표를 확보해서 전략적으로 측정하는 거, 산업 규제를 미리 식별하고 용이하게 해라는 부분도 전략적으로 필요함
    - 자동화 도구는 반대로 AI 이후에 모든 데이터를 가지고 사용을 했을 경우에 표로 생각을 해봤었음
    
- 16:21~17:19
    
    데이터의 품질 측정
    
    - 데이터의 유용성, 안전성, 유효성, 일관성 정확성을 기준으로 여러 가지 분석 결과를 나타낼 수 있게 설정할 수 있음
    - 데이터의 품질 측정은 과거에 정해져 있는 화면과 규칙으로 설계가 가능하지만 프로티가 옷에 의해서 변명을 하거나 오퍼레이션을 할 수 있음
    - 생성형 AI에게 붕괴 징후 프로시의 징후가 있음
    
- 18:19~22:25
    
    의료 데이터 품질 측정
    
    - 의료 쪽 데이터 사업을 많이 하고 있음
    - 의료 데이터에 대해서 품질 측정을 하거나 파악하는 경우가 많음
    - 데이터 품질을 측정하기 위해서는 가장 중요한 게 데이터 표준도 중요하고 거버넌스도 중요하겠지만 빨리 돌릴 수 있는 측정을 하는 데 한 달 걸리면 쫓겨남
    - 데이터 표준화 또는 오류 수정을 할 수 있는 상단에 데이터 구조에서 제안을 다시 드렸었음
    
- 23:09~25:32
    
    생성형 AI의 특징
    
    - 와이즈 스톤에서 인공지능에 대한 신뢰성을 연구하고 있고 올해 신뢰성 인증을 고도화 중에 있음
    - 생성형 AI에 대해 설명하고 있음
    - 생성형 AI는 사용자 입력에 따라서 창의적으로 다양한 출력을 생성하는 기능을 가지고 있음
    - 생성형 AI는 확장성, 창의성, 자동화, 창의적인 대화를 통해 점진적으로 결과를 개선하는 부분이 있음
    
- 26:33~29:12
    
    생성형 AI의 패러다임
    
    - 생성형 AI에서 가장 중요한 부분은 프로포트라고 생각함
    - 프로포트를 어떻게 입력을 하느냐에 따라서 내가 원하는 결과를 받아볼 수 있음
    - 프로포트는 내가 원하는 바를 한 줄로 작성해서 입력을 해서 응답을 받으면 되는 것임
    - 생성형 AI가 사용되는 패러다임은 기존에 저희가 커피 자판기로 검색하는 게 아니라 어떤 스타일의 가격대는 얼마에 어떤 요건들을 가지고 있는 제품들을 보여줘라고 하는 형태처럼 새로운 패러다임을 가지고 갈 것으로 보임



**단락별 요약

**

평가 전더보기

- 00:00~01:02
    
    KT, 독자 모델 개발
    
    - KT가 독자 모델을 만들고 있음
    - 모델들을 스튜디오 인프라 뒤에 패럴날하게 구성을 해놓고 앞에 오케스트레이터를 구성함
    - 고객의 사용하는 쿼리가 적절하게 요청이 오면 그 요청되는 쿼리 기반으로 해서 gpt4 모델을 활용함
    
- 01:43~02:05
    
    도메인 특화 모델
    
    - 특정 도메인에서 활용을 하기 위해서는 도메인 특화 모델이 필요함
    - 도메인 특화 모델은 미음 모델이나 오픈 모델을 기반으로 튜닝한 모델을 활용함
    - 에이전트는 기본적으로 커리가 들어오면 쿼리가 들어온 걸 기반으로 리즈닝을 하고 어떤 일을 해야 되지 플래닝을 진행을 하고 플래닝 된 거 기반으로 해서 외부의 툴들을 호출을 하고 호출된 걸 기반으로 해서 응답을 처리하게 됨
    
- 02:48~06:42
    
    한국적 AI를 위한 요소
    
    - 한국적 AI를 하기 위해서는 한국의 정신이나 방식이나 지식에 따라서 미묘하게 달라지는 부분들을 고려한 에이전트들을 만드는 것들이 중요한 요소라고 생각을 하고 있음
    - 한국적 AI를 하기 위해서는 한국의 데이터나 개인 정보가 해외로 나가면 안 되는 개인정보법이나 보안 이슈들이 중요함
    - 한국적 AI를 보장하는 크리스마스볼 AI 프레임웍을 가지고 진행을 하는 것들이 중요함
    
- 07:41~08:25
    
    데이터의 신뢰성
    
    - 데이터의 투명성, 릴라이어빌리티, 데이터의 신뢰성, 모델의 품질을 관리하는 것이 중요함
    - rai 측면에서 인식 제고나 교육도 중요한 분야로 보고 있음
    
- 09:26~13:24
    
    한국적 AI의 품질 확보
    
    - 한국적 AI에 대한 LLM 품질을 확보하기 위해서 크게 5가지의 원칙을 가지고 진행을 하고 있음
    - 한국적 AI뿐만 아니라 기본적으로 LLM에 대한 품질을 확보하기 위해서 필요한 요소이기도 함
    - 첫 번째로는 AI 학습 데이터에 대한 거버넌스에 대한 관리를 명확하게 잘 해야 되는 부분들이 있음
    - 두 번째가 체계화된 평가 프로세스를 운영을 하면서 모델들이 자칫 저희가 개발 내부에서도 그렇고 여기 계신 분들도 개발을 하다 보면 일정에 쫓겨서 테스트를 좀 스킵하고 넘어가고 싶은 욕심들이 많이 생기는데 체계화된 평가 프로세스를 통해서 그런 부분들을 방지를 하고 모델의 품질을 올리는 작업들을 진행을 하고 있음
    
- 13:38~16:02
    
    데이터 모델 관리
    
    - 데이터 품질 관리를 진행하는 부분들을 기반으로 해서 만들어진 학습 데이터 카탈로그를 기반으로 해서 사내에 각 모델을 만드는 팀에 데이터들이 서빙이 되고 모델이 만들어질 때는 데이터 카탈로그에 어떤 몇 번 몇 번의 데이터들을 활용을 해서 모델을 만들었는지가 다 남게 됨
    - 만들어진 모델은 어떤 데이터를 가지고 학습을 했는지가 내부적으로는 다 관리가 되고 있음
    - 데이터 모델에 대한 편향성이나 이런 부분들을 최소화하기 위해서 데이터를 그냥 모으는 게 아니라 데이터가 모아지면 이 모아진 데이터를 한국적 AI를 기준으로 해서 30여 개 분야로 분류를 좀 나눔
    - 도메인 분류에 맞는 데이터들이 어느 정도의 어떤 양으로 분포가 돼 있는지 이런 부분들을 관리를 해서 그걸 기반으로 해서 학습을 진행하게 됨
    
- 16:45~20:09
    
    AI 학습 데이터 카탈로그
    
    - 처리가 된 데이터를 기반으로 해서 다시 한 번 개인 정보 필터링 API랑 톡식 필터링이 API를 통해서 유해 정보나 개인 정보들을 다 걸러내면 이런 것들을 기반으로 해서 데이터에 대한 2차 품질 평가를 진행을 하고 최종적으로 모델을 학습할 수 있는 AI 학습 데이터 카탈로그가 완성이 되게 됨
    - 모델을 만들 때 모델의 목적을 먼저 설정을 하고 설정된 목적에 맞춰서 평가 지표를 수립하는 게 제일 먼저 선행되어야 함
    - 모델을 학습이 진행이 되면 마지막으로 모델 평가나 분석 과정을 진행을 해서 이 사이클을 계속 반복을 하면서 모델이 만들어지게 됨
    
- 21:00~23:28
    
    KT의 모델 평가
    
    - KT는 평가 데이터셋을 공유하지 않는 보안 체계를 가지고 있음
    - 평가 지표를 공유하고 모델을 학습할 때 주안점으로 학습해야 되는지는 알아야 되기 때문에 평가 지표를 공유함
    - 평가 결과는 기존 버전별로 누적을 해서 모델에 대한 평가를 관리하고 시장에 나와 있는 다른 경쟁 모델 대비 비교를 하는 방식으로 모델 평가를 최종적으로 보고 있음
    
- 24:24~25:47
    
    클라우드 네이티브 전환
    
    - 정부 24, 일자리 플랫폼 등 9개가 클라우드 네이티브로 전환을 하겠다고 공식적으로 발표가 됨
    - 소프트웨어의 발전이 마이크로 서비스 아키텍처 중심으로 개발을 하고 있음
    - 컨테이너 기술 개발이 상당히 중점적으로 적용이 되고 있음
    - AI 인공지능 부분은 말하기가 무색할 정도로 많은 부분에서 적용이 되어 있음
    
- 26:35~27:29
    
    음성 기반의 서비스 검증
    
    - 음성에 대한 검증 그리고 음성 기반의 사용자 경험을 최적화 최적화해서 서비스할 수 있도록 검증을 함
    - 테스트를 간단하게 어떻게 진화됐는지를 설명을 드리겠음
    - 기능 중심의 서비스를 검증할 때는 매뉴얼 테스트를 많이 했음
    - 반복적인 테스트를 자동화하는 요구가 늘어나고 다양한 도구들 셀레늄이라든지 젠키스 등의 CICD 도구들을 도입해서 자동화하는 영역으로 확장이 됨
    - 현재는 AI를 접목해서 테스트를 자동화할 수 있는 거로까지 진화가 됨
    
- 28:18~32:04
    
    AI 컨택센터의 핵심 기술
    
    - AI 컨택센터를 운영하기 위한 핵심 기술은 음성을 인식해야 되는 거고 그다음에 사람이 말하는 거의 의미를 파악해야 되기 때문에 자연어 처리 기술이 필요함
    - 대화형 AI, 음성 합성 기술, 음성 인식 기술, 멀티턴 시나리오 개념의 대화형 인터페이스 구축이 필요함
    - gx 기반의 AI 파피스 센터의 관리 자동화의 대표적인 그림을 보여주고 설명함
    
- 32:55~33:46
    
    패스페이의 판단 방식
    
    - aicc가 응답한 결과를 말로 함
    - 음성을 텍스트로 변환을 해야 함
    - 변환된 텍스트와 시나리오에서 갖고 있는 기대 응답 결과를 비교해서 패스페이를 판단하는 방식으로 진행함
    
- 34:43~37:35
    
    음성 인식 시스템의 과제
    
    - 음성 인식 시스템에서 다양한 언어와 소음에 영향을 받지 않아야 되는 과제가 있음
    - 음성 인식 시스템에서 다양한 발음이나 잡음의 정확도를 유지하고 에러율을 최소화할 수 있는 방안을 만들어야 됨
    - 대화와 AI가 멀티턴 시나리오에서 이전 대화를 이해를 하면서 문맥상 의미가 아예 다른 내용으로 대답하지 않게 의미를 같이 가는 어떤 그런 맥락을 유지해 가는 부분들에 대해서도 평가가 필요하고 검증이 필요함
    
- 38:36~41:38
    
    테스트 자동화의 이슈
    
    - 데이터가 다양하게 달라질 수 있는 구조를 자동화해서 구현하기 위해서 템플릿 시나리오의 표형 템플릿을 구성함
    - 음성에 대한 검증 판단하기 위한 유사도 측정 부분들에 대한 모듈들 많이 들어감
    - 테스트 자동화 수행 환경을 랩이라는 걸 이용해서 테스트 옵스를 구축해 드림
    - 테스트 옵스를 구축하는 방식으로 진행을 하면서 두 가지의 이슈를 발견함
    - 변화의 독립적인 검증 자동화 운영 체계가 필요함
    - 데이터가 주기적으로 바뀜
    
- 42:22~43:19
    
    음성 분석 전략
    
    - 음성에 대한 검증 자동화를 진행하기 위해서 어떻게 분석했고 어떻게 설계했고 운영을 어떤 방식으로 하는 전략을 세웠는지를 간단하게 말씀을 드리겠음
    - VX 검증 제도 분석 전략을 말씀드리겠음
    - 응답 유형별 분석, 시나리오 유형별 분석으로 두 가지 팩터로 구분을 했음
    
- 44:17~47:54
    
    자동화 범위 선정
    
    - 자동화 범위를 선정할 때 독립적인 PC로 연계되거나 이런 것들을 배제하고 질의응답과 5월까지만 범위를 잡음
    - 자동화를 설계할 때 가변 데이터 검증 데이터 관리가 필요함
    - 검증 시나리오 템플릿을 표준화해서 표준 스펙을 정리하는 방식으로 진행함
    - 운영 전략은 사용자가 지랄을 활용해서 편하게 운영을 해야 되기 때문에 이슈의 유형들 필드의 유형들을 다 정리해서 활용할 수 있게 정리함
    
- 48:45~52:43
    
    테스트 플랜 생성
    
    - 테스트 플랜을 생성한 후 테스트 케이스를 갖고 실사용 시나리오를 생성하고 검증하는 과정을 보여줌
    - 테스트 플랜에서 TC를 선택하고 스테터스를 인프로그레스로 변경을 하면 긴 파이프라인으로 연동이 됨
    - 테스트 플랜에서 테스트 데이터를 입력하고 전화를 거는 것은 기능 테스트의 일부임
    - 디백이 났을 때 디백 이슈를 자동 생성하는 것까지가 영상의 전체 모습임
    
- 52:50~54:43
    
    AI 시스템의 품질 평가
    
    - AI 시스템의 품질 평가를 위한 측정 및 가이던스 국제 표준 설계 및 개발 현황이라는 주제로 한국산업기술시험원 안선호 팀장님께서 발표해 주시겠음
    - 품질 평가의 정의에 대해서 가지고 왔음
    - 품질 평가가 왜 필요하냐면 여러 가지의 중요 요소들이 있음
    
- 55:57~59:04
    
    품질 평가의 중요성
    
    - 품질 평가에 있어서 가장 중요한 건 퀄리티 레저라고 생각함
    - s42 내에서 품질 AI 시스템에 대한 품질 평가를 하기 위해서 어떤 표준들을 개발하고 있는지를 설명하고 있음
    
- 01:00:06~01:02:34
    
    AI 시스템 표준화
    
    - sc 42는 5개의 워킹 그룹으로 구성되어 있음
    - 워킹그룹 1은 AI 시스템과 관련된 표준들을 개발함
    - 워킹그룹 2는 데이터와 관련된 표준들을 개발함
    - 워킹그룹 3은 AI의 신뢰성과 관련된 표준들을 개발함
    - 워킹그룹 4는 기술적인 AI 시스템에 대한 표준들을 개발함
    
- 01:03:31~01:04:28
    
    조인트 워킹 그룹 2
    
    - 조인트 워킹 그룹 2는 AI 시스템에 대한 테스팅과 VMV에 관련된 표준을 개발함
    - 조인트 워킹 3는 헬스 인포메틱 인포메이션, 의료 정보학과 관련된 기술위원회랑 같이 표준들을 개발함
    - 조인트 워킹 그룹 4는 펑셔널 세이프티와 관련된 표준들을 한창 개발 중에 있음
    - 조인트 워킹 5는 NLP 자연어 처리와 관련된 표준들을 TC 37과 같이 표준을 개발함
    - 작년에 수립된 합동반 조인트 워킹 그룹인데 AI 시스템과 관련돼서 어떤 시험과 인증을 하기 위해서는 제트 워킹그룹 스스에서 개발되고 있는 표현들을 적용을 해야 함
    
- 01:05:24~01:07:36
    
    AI 표준 개발
    
    - s42에서 어떤 표준들을 개발했는지를 정리해 봄
    - 워킹 그룹 원에서 AI 기반 및 개념 관련된 표준들을 개발함
    - AI 프레임워크와 관련된 25,054 표준을 기본에서 개발함
    - AI 조직과 관련된 표준이 4만 2천인 표준을 개발함
    - AI 생명주기 프로세스의 표준인 5338 표준을 개발함
    - AI 시스템이 어떤 영향 평가를 어떤 외부나 어떤 이해관계자에게 어떤 영향을 평가 영향을 미치는지를 평가할 수 있는 표준인 4만 2천 원 표준을 개발함
    - AI 거버넌스 관련된 3807 표준이라든지 리스크 관리 표준들을 개발함
    - AI 신뢰성 관련해서는 편향성이라든지 윤리사회적 문제 표준 그리고 컨트롤빌리티, AI 시스템에 대한 재활 통제에 관련된 표준들 등의 다양한 표준들이 개발됨
    
- 01:08:30~01:10:27
    
    AI 시스템에 대한 품질 모델
    
    - AI 시스템에 대한 품질 모델을 s 42에 2059라는 표준에서 다루고 있음
    - 현재 개정 작업 중에 있음
    - AI 시스템에 대한 품질 모델을 개발했을 당시에는 퍼스트 에디션으로 개발이 됨
    - 현재는 2만 5천 10도 개정이 됐고 AI 시스템에 대한 품질 모델도 개정이 필요하다라고 생각이 들어서 현재 개정 작업 중에 있음
    
- 01:11:30~01:13:05
    
    AI 시스템 품질 특성에 맞는 레저먼트 표준
    
    - AI 시스템에 대해서 품질 평가를 하기 위해서 새로운 AI 시스템 품질 특성에 맞는 레저먼트 표준이 필요함
    - AI 시스템 품질 특성에 맞는 새로운 레저먼트 표준을 만들자라고 해서 제안을 함
    - 투표 중에 있다고 말씀드림
    
- 01:14:10~01:15:16
    
    AI 시스템 표준 제안
    
    - AI 시스템에 대한 매지먼트 할 수 있는 표준이 필요하다고 생각이 들어서 표준을 제안하게 되었음
    - 기존에 있던 표준은 isic ts25,058임
    - 새로 제안한 표준은 매니저먼트 앤 가이던스 퀄리티 이베러시하고 AI 시스템임
    
- 01:16:17~01:19:25
    
    표준화의 필요성
    
    - 표준은 레저먼트엔 가이던스 보 퀄리티 이베레이션을 위한 시스템이고 SDT라고 해서 스탠다드 디벨롭먼트 트랙임
    - 표준이 완성되기까지는 시간이 걸릴 것 같음
    - 표준이 나오기 전까지는 기존의 25,058과 250 2 3을 사용해서 품질을 평가를 할 수밖에 없음
    
- 01:20:18~01:24:29
    
    AI 퀄리티 매저
    
    - AI 시스템이 정말 AI 제품이 맞아라는 퀘스천이 생길 때 평가할 수 있는 퀄리티 매저임
    - 어떤 정의돼 있는 AI 모델을 위해서 어떤 펑션이 수행된다고 정의돼 있는데 그게 정말로 그렇게 수행되고 있어를 평가하는 항목임
    - 모델의 정확성이라든지 머신러닝 파스크에 대한 정확성이라든지 다양한 퀄리티 모드들을 지금 제가 초안에 아웃 라이너에 잡아서 B2B를 던지기는 했는데 그런 부분은 좀 다 오늘 자리에 발표를 하기엔 힘들 것 같아서 여기까지만 좀 가져왔다고 말씀드리고 싶음