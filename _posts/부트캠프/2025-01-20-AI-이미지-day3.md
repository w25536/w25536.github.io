---
title: "Ai 심화 Day3"
last_modified_at: 2025-01-20
categories:
  - 부트캠프
tags:
  - python
  - 파이썬
  - torchtext
  - pytorch
  - 파이토치
  - 전처리
  - data science
  - 데이터 분석
  - 딥러닝
  - 딥러닝 자격증
  - 머신러닝
  - 빅데이터
excerpt: "Ai 심화 Day3 정리"
use_math: true
classes: wide
---

## Conv2d

Filter bias와 spatial dimensions == depth

<https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html>

![](https://blog.kakaocdn.net/dn/buTDig/btrUNWinaGI/Up3sBWkF1divFGgkP4DF2k/img.gif)

**Naive Convolution**

![](https://blog.kakaocdn.net/dn/bpzdOE/btrUSukFrys/m8pk4doUidUAMASsLD5Ez0/img.gif)

**Atrous Convolution**

![](https://blog.kakaocdn.net/dn/bjS7OO/btrUNqRBVaK/civUAMDkqkDr2Y1MYM1yb1/img.gif)

**Transposed Convolution**

### U-Net 이해

`torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)`

![](https://velog.velcdn.com/images/not12m10/post/1397fbde-00d8-4d8b-8c5c-62bf9acf7cad/image.gif)

![](https://velog.velcdn.com/images/not12m10/post/f3c02918-fca1-4c29-8dde-ff0aa888ab76/image.gif)

---

## 1. 합성곱 신경망

### (Global) Average Pooling

- **1D**: 시간축으로
- **2D**: 이미지
- **3D**: 필터도 3차원을 가진 3D 입력을 갖는 2D 합성곱

Fashion MNIST size: 28 x 28

### Batch Normalization 알고리즘 분석

- <https://eda-ai-lab.tistory.com/406>

### 논문 읽고 분석하기

- <https://arxiv.org/abs/1505.04597>

## FCN (Fully Convolutional Networks)

### Pixelwise Prediction

- Upsampling을 하여 dense map을 얻는 방법으로 **2가지 방법**이 소개된다
- Feature map 객체수를 동일하게 맞춰준다
- 고양이에 대한 heatmap이 낮은 걸 upsampling 시킨다 - feature map을 만들어준다

**FCN 과정:**
1. Convolution 통해서 feature 추출
2. 동일하게 맞추고
3. Upsampling 시키고
4. 최종 feature map과 정답과 학습을 한다

**VGG 구조:**
224×224 → (pooling) → 112×112 → 56×56 → 28×28 → 14×14 → 7×7 → 1×1

Coarse(대략적인) 정보를 얻고 있다.

FCN은 fully connected layer 없고 1×1 convolution 사용. 슬라이드에 표현은 없지만 ReLU 함수를 통해서 출력을 한다.

Pooling 대신에 stride 2를 사용하여 줄여주는 경우도 있다.

작은 픽셀 크기를 크게 만들면 성능이 떨어진다.

### FCN-32s, FCN-16s, FCN-8s

conv → conv → pooling → conv → conv → pooling → conv → conv → conv → pooling → conv → conv → conv → pooling → 1×1 conv

중간에 1×1 conv feature map 사용한다. 4번째가 6번째보다 feature map에서 조금 더 중요한 정보를 얻는다(왜? 점점 줄어들어서).

그래서 6번에서의 upsampling 한 것과 4번의 skip connection을 통해서 최종 출력을 한다.

![](https://miro.medium.com/max/700/1*5LhYXkhBg6kwbR1zN5Eg8g.png)

![](https://wikidocs.net/images/page/143443/FCN-16S.png)

![](https://wikidocs.net/images/page/143443/FCN-8S.png)

Upsampling 하면 해상도가 떨어져 안 좋아서 Encoder와 Decoder 사용해서 해결.

nnUNet은 의료계에서 탑으로 자리매김하고 있다.

## Encoder-Decoder 구조

- **Encoder**: 정보를 압축
- **Decoder**: 정보를 풀어줌. 원래 정보를 복원하면서 고해상도 이미지를 가지고 있다

### Upsampling Techniques

- Pooling 한 걸 다시 unpooling 한 것
- Transpose convolution

![](https://velog.velcdn.com/images%2Fhayaseleu%2Fpost%2F8abde504-c3b1-4a40-a17d-16ad230ccead%2F1_WpOcRWlofm0Z0EDUTKefzg.gif)
![](https://velog.velcdn.com/images%2Fhayaseleu%2Fpost%2F36c9c660-27c3-40f3-a08c-335bf67610c1%2F1_34_365CJB5seboQDUrbI5A.gif)
![](https://velog.velcdn.com/images%2Fhayaseleu%2Fpost%2F9457f703-acb1-443f-a450-8f1f834396dc%2F1_gXAcHnbTxmPb8KjSryki-g.gif)

## U-Net 구조

- 양쪽으로 대칭 구조
- 각 step마다 pooling이 포함되어 있다
- 다운 샘플링 할 때마다 2배씩 채널 수 증가
- Convolution & ReLU (최근에 LeakyReLU 사용하는 추세)
- Pooling()

**채널 수 변화:** 64 → 128 → 256 → 512 → 1024

### Bottleneck

Encoder 부분에 압축되어 있다. 인코더를 통해 가장 축소된 해상도 (가장 깊은 레이어)

### Decoder (Expanding Path)

- Transposed Convolution (Deconvolution)
- 업샘플링 + 학습
- 2×2 up convolution

## 손실 함수 (Loss Functions)

### 1. Binary Cross Entropy (BCE)

CrossEntropy인데 Binary인 경우 사용한다. 픽셀이 foreground인지 background인지 판단.

### 2. Dice Loss

- 두 이미지 간의 유사도를 측정하는 손실 함수
- p는 예측 값 (0~1 사이) prediction
- y는 실제 값 (0~1 사이) ground truth → 실제 값
- Prediction과 ground truth가 얼마만큼 겹치는가? (overlap)

### 3. Focal Loss

<https://minimin2.tistory.com/179>

**Hard Example 가중치:**
1. Hard Example Mining (OHEM, Online Hard Example Mining)
2. Weighted BCE
3. Focal Loss

Pixel별로 분할하는 것이다.

- **Weighted BCE**: 적은 양의 클래스에 더 큰 가중치를 준다
- **Focal Loss**: 예측 확률 Hard example에 가중치를 준다. 잘 틀리는 것에 더 큰 가중치를 주어서 잘 맞게 하지만 단점은 밸런스가 깨진다

### Dice Coefficient vs IoU

- **Dice Coefficient**: P(prediction)과 y(ground truth) 각각 더하고 곱한 후 계산
- **IoU (Intersection over Union)**: 일반적으로 사용되는 손실 함수
- **Dice**: 의료 영상에서 주로 사용

## 평가 지표

### Precision (정확도)

True로 **예측한** 분석대상 중에서 **실제 값**이 True인 비율을 말하며, 모형의 정확성을 나타내는 지표가 된다. 정확도가 높다는 것은 False Positive(**실제 False를 True로 잘못 예측**) 오류가 적다는 말이다.

![](https://www.simplilearn.com/ice9/free_resources_article_thumb/5-precision.JPG)

### Recall (재현율)

**실제 값**이 True인 분석대상 중에서 True로 **예측**하여 모형이 적중한 비율을 말하며, 모형의 완전성을 나타내는 지표이다. 재현율이 높다는 것은 False Negative(**실제 True를 False로 잘못 예측**) 오류가 낮다는 뜻이다.

![](https://www.simplilearn.com/ice9/free_resources_article_thumb/recall.JPG)

> [!NOTE] 의료 데이터에서의 Confusion Matrix
> 의료 데이터에서는 **Recall이 중요**하다. 왜냐하면, 병 걸린 사람을 검사했을 때 오진이 나오면 안 되기 때문이다. 기본적으로 병원에서는 True/False(병의 유무)를 여러 단계를 거쳐서 검사를 진행한다. 우선은 비교적 간단하지만, 정확도가 떨어지는 test를 먼저 진행한다. 그리고 병에 걸릴 가능성이 있다면 재검사를 통해 정확도가 높은 test를 진행하는 방식을 사용한다. 예를 들면, MRI를 찍고 다른 가능성이 있으면 혈액검사 같은 추가 검사를 진행하는 것과 같다. 정리하면, 처음부터 모든 검사를 다 할 수 없으니 간단한 검사부터 해서 좁혀나가는 것이다. 이러한 방식은 Recall이 좋아야 병을 찾아나갈 수 있다.
> 
> 물론 최종적으로는 Recall과 Precision이 둘 다 좋은 비싼 방법을 사용할 것이다. 그러나 초반의 경우, 데이터를 쉽게 얻을 수 있는 것들을 조합하거나 recall을 더 중요시 한다. 여기서 주의할 점이 Recall만 100% 몰빵을 하면, Precision이 0이 될 수도 있다. 예를 들면, 무한대의 환자가 왔을 때 너 무조건 병이 있다고 하면 Recall은 100%가 된다. 하지만 Precision은 n/무한대가 되므로 0으로 가까워진다. 병 안 걸린 사람도 병 걸린 사람이 되기도 한다. 따라서 **Recall을 100%로 만드는 것은 바람직하지 않고, 0.9나 95% 이상으로 유지하면서 Precision을 떨어뜨리지 않는 것이 중요하다.**

## U-Net의 장점

### 왜 U-Net에서 좋은 성능을 보이는가?

1. **소량 데이터로도 괜찮은 성능**을 보인다
2. **경계 정보 복원에 유리**하다
3. 원 논문에서 ISBI Cell Tracking 등에서 좋은 성능을 보여준다

## 데이터 전처리 및 학습 기법

### 데이터 전처리
- 정규화

### 데이터 증강
- 회전, 플립, 스케일, 노이즈 추가
- 의료 영상 특성상, 고도한 왜곡은 주의

### 과적합 방지
- Regularization, Dropout, Early Stopping
- Cross Validation (데이터가 적을 때 유효)

## U-Net 변형 모델들

- **Attention U-Net**: Attention gate로 주요 영역 강조
- **SegNet**
- **DeepLab**
- **PSPNet**

## U-Net 핵심 정리

**Encoder - Decoder + Skip Connection = 정밀 분할**

- 의료 영상에서 탁월한 성능, 다양한 확장형 모델 존재
- 소량 데이터, 경계 정보에 매우 효과적

### 질문들

**Q1)** Skip connection 제거 시 성능 차이?

**Q2)** 고해상도 이미지 메모리 문제 해결법?

**Q3)** 다른 세그멘테이션 모델과의 성능 비교?
