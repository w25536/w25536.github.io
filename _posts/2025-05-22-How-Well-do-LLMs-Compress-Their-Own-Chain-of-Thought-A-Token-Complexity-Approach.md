---
title: "[논문리뷰] How Well do LLMs Compress Their Own Chain-of-Thought? A Token Complexity Approach"
last_modified_at: 2025-05-22
categories:
  - 
tags:
  - 
excerpt: "[논문리뷰] How Well do LLMs Compress Their Own Chain-of-Thought? A Token Complexity Approach"
use_math: true
classes: wide
---



> arXiv 2025 [Page](https://arxiv.org/pdf/2503.01141)]
> Ayeong Lee, Ethan Che, Tianyi Peng
> Affiliations not specified
> 3 Mar 2025 (v1), last revised 1 Apr 2025 (v2)



**논문 정리**

1. 개요
이 논문은 llm(대규모 언어 모델)이 복잡한 추론 과제를 해결하는 데 효과적인 기술인 cot(chain-of-thought) 프롬프팅을 사용할 때, 추론 길이와 모델 성능 간의 관계를 체계적으로 분석합니다. 다양한 압축 지침을 통해 추론 길이를 줄이면서도 정확도를 유지하는 방법을 탐구하며, 추론 길이와 정확도 사이에 trade-off가 존재함을 밝힙니다. 각 과제에는 성공적인 문제 해결에 필요한 최소한의 토큰 수인 '토큰 복잡성'이라는 고유한 값이 있으며, 이는 최적의 정확도-압축 trade-off에 대한 상한을 계산하는 데 사용될 수 있습니다. 연구 결과는 프롬프트 기반 압축 전략이 이론적 한계에 훨씬 못 미친다는 것을 보여주며, 이는 추론 효율성을 개선할 여지가 크다는 것을 시사합니다. 이 연구는 llm이 쉬운 질문에 대해 더 짧은 응답을 제공하는 적응적 추론 능력을 측정하는 데 유용한 도구인 토큰 복잡성을 강조한다.

2. LLM 응답 길이와 정확성 간의 관계
LLM에 대한 여러 프롬프트를 고려함으로써 사고의 연쇄와 응답 길이 간의 스펙트럼을 유도할 수 있다. No CoT는 정확도가 가장 낮고, Default CoT는 일반적으로 가장 높은 성능을 나타낸다.
프롬프트에 따라 응답의 길이를 효과적으로 줄일 수 있으며, BeConcise는 성능에 큰 영향을 주지 않고도 토큰 길이를 줄이는 데 성공한다.
다양한 프롬프트가 적용될 때 단점이 없는 누적적인 유니버설 트레이드오프가 존재하며, 각 프롬프트에 따라 유사한 정확도와 응답 길이 패턴이 형성된다.
응답 길이가 이상적인 임계값을 초과해야만 LLM이 정답을 맞출 수 있다는 점에서, 응답 길이가 올바른 답변과 밀접한 관계가 있음을 보여준다.
토큰 복잡성 가설은 문제의 난이도와 필요 토큰 수의 관계를 설명하며, 이는 각 LLM에서 고유하게 적용될 수 있는 유용한 지표로 여겨진다.

3. 토큰 복잡성 가설과 추론 성능
토큰 장의 길이는 질문 수준에서 성능 예측에 있어 높은 예측력을 가지고 있으며, 길이가 특정 임계값을 초과할 때 추정 정확도가 매우 높은 것으로 나타난다.
임계값 분류기가 더 능력 있는 모델(예: GPT-4o, Claude 3.5 Sonnet)과 더 쉬운 벤치마크(예: GSM8K)에서 높은 평균 분류 정확도를 기록한다.
토큰 임계값 분류기는 실제 정확도와 예측된 정확도간의 평균 상대 오차를 6% 이내로 유지하며, 큰 모델에서 더 작은 오류를 보이므로 추론성능 예측을 위한 유효한 모델로 판단된다.
최적 토큰 할당 아래에서의 요구 토큰 수를 계산할 수 있으며, 이 수치는 기존 프롬프트 전략의 평균 토큰 길이보다 훨씬 작을 수 있다.
토큰 복잡성은 추론역량의 중요한 척도로 작용하며, 동일한 정확도를 달성하는 두 모델 간 평균 토큰 복잡성의 차이를 통해 성능을 비교할 수 있다.

4. 고차원적인 토큰 압축과 성능의 관계
토큰 복잡성 가설은 최적의 사고 사슬 압축 방식을 통한 효율성의 한계를 제공하며, 이는 문제 난이도에 대한 질문을 더 쉽게 하기 위해 더 짧은 사고 사슬을 사용하는 압축의 중요성을 강조한다.
Han et al. (2024)의 TALE-EP 절차는 LLM이 질문을 해결하는 데 필요한 최소 토큰 수를 추측하고, 그 추측한 수를 기반으로 단계적으로 사고하도록 유도한다.
실험 결과에 따르면, LLM이 사고 노력을 적응적으로 조정할 때 정확도와 토큰 길이의 상관관계를 살펴볼 수 있으며, TALE-EP는 기존의 간단한 프롬프트 전략보다 정확도가 떨어지는 것으로 나타났다.
TALE-EP의 토큰 수는 진짜 토큰 복잡성과 높은 상관관계를 보이며, 이는 LLM이 문제의 난이도에 따라 응답 길이를 자연스럽게 조정할 수 있음을 시사한다.
연구는 이를 통해 LLM의 응답 길이를 개선하기 위한 새로운 방법론의 성과를 비교하고, 기존 압축 전략들이 최적의 정확도-길이 경계에서 크게 벗어나 있음을 보여준다.

5. LLM의 정확도-길이 트레이드오프 분석
LLM의 추론 길이와 성능 간의 관계에 대한 이해는 새로운 통찰을 제공하며, 이 연구는 수학적 추론에 국한된다.
데이터는 다양한 프롬프트에 대한 토큰 복잡성을 평가하여, LLM의 성능이 프롬프트의 난이도에 따라 어떻게 달라지는지를 분석한다.
하지만, 프롬프트 수에 제한이 있어, 보다 넓은 압축 전략을 탐색하면 압축 한계를 확장할 수 있을 것으로 예상된다.
프롬프트에 따라 성능 차이가 있음을 보이며, 특히 LLM이 문제를 해결하는 방식이 필요에 따라 달라진다.
최고 성능의 LLM은 생성된 응답 길이가 문제 난이도와 잘 맞아 떨어지지만, 여전히 긴 체인을 생성하는 경향이 있다.